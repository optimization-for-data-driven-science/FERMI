{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uofE2o7xpScU"
      },
      "outputs": [],
      "source": [
        "#@title Import Modules\n",
        "import io\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import tempfile\n",
        "import time\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toxicity_data_url = (\"https://github.com/conversationai/unintended-ml-bias-analysis/\"\n",
        "                     \"raw/e02b9f12b63a39235e57ba6d3d62d8139ca5572c/data/\")\n",
        "\n",
        "data_train = pd.read_csv(toxicity_data_url + \"wiki_train.csv\")\n",
        "data_test = pd.read_csv(toxicity_data_url + \"wiki_test.csv\")\n",
        "data_vali = pd.read_csv(toxicity_data_url + \"wiki_dev.csv\")\n",
        "\n",
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zCAfGCYspvvd",
        "outputId": "9f7bcfe9-0f2f-4845-c494-42064e23037b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            rev_id  toxicity  \\\n",
              "0           2232.0       0.1   \n",
              "1           4216.0       0.0   \n",
              "2          26547.0       0.0   \n",
              "3          37330.0       0.3   \n",
              "4          37346.0       0.1   \n",
              "...            ...       ...   \n",
              "95687  699822249.0       0.2   \n",
              "95688  699826615.0       0.0   \n",
              "95689  699843603.0       0.0   \n",
              "95690  699848324.0       0.0   \n",
              "95691  699891012.0       0.4   \n",
              "\n",
              "                                                 comment  year  logged_in  \\\n",
              "0      This: :One can make an analogy in mathematical...  2002       True   \n",
              "1      `  :Clarification for you  (and Zundark's righ...  2002       True   \n",
              "2      `This is such a fun entry.   Devotchka  I once...  2002       True   \n",
              "3      `   I fixed the link; I also removed ``homeopa...  2002       True   \n",
              "4      `If they are ``indisputable`` then why does th...  2002       True   \n",
              "...                                                  ...   ...        ...   \n",
              "95687  `  :``Comment````. Gentlemen, this article pro...  2016       True   \n",
              "95688   *Support and recommend moving this (and my re...  2016       True   \n",
              "95689  `  == File:Romantic Warriors cover.jpg ==  You...  2016       True   \n",
              "95690  `   These sources don't exactly exude a sense ...  2016       True   \n",
              "95691    == Warning ==  There is clearly a protection...  2016       True   \n",
              "\n",
              "            ns   sample  split  is_toxic  \n",
              "0      article   random  train     False  \n",
              "1         user   random  train     False  \n",
              "2      article   random  train     False  \n",
              "3      article   random  train     False  \n",
              "4      article   random  train     False  \n",
              "...        ...      ...    ...       ...  \n",
              "95687  article  blocked  train     False  \n",
              "95688  article   random  train     False  \n",
              "95689     user   random  train     False  \n",
              "95690  article  blocked  train     False  \n",
              "95691     user  blocked  train     False  \n",
              "\n",
              "[95692 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6745fa7f-4a48-486d-9d76-fe40211dbeb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev_id</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "      <th>is_toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2232.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>This: :One can make an analogy in mathematical...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4216.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>`  :Clarification for you  (and Zundark's righ...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>user</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26547.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>`This is such a fun entry.   Devotchka  I once...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37330.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>`   I fixed the link; I also removed ``homeopa...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37346.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>`If they are ``indisputable`` then why does th...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95687</th>\n",
              "      <td>699822249.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>`  :``Comment````. Gentlemen, this article pro...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>blocked</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95688</th>\n",
              "      <td>699826615.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>*Support and recommend moving this (and my re...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95689</th>\n",
              "      <td>699843603.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>`  == File:Romantic Warriors cover.jpg ==  You...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>user</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95690</th>\n",
              "      <td>699848324.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>`   These sources don't exactly exude a sense ...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>blocked</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95691</th>\n",
              "      <td>699891012.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>== Warning ==  There is clearly a protection...</td>\n",
              "      <td>2016</td>\n",
              "      <td>True</td>\n",
              "      <td>user</td>\n",
              "      <td>blocked</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95692 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6745fa7f-4a48-486d-9d76-fe40211dbeb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6745fa7f-4a48-486d-9d76-fe40211dbeb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6745fa7f-4a48-486d-9d76-fe40211dbeb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels\n",
        "labels_train = data_train[\"is_toxic\"].values.reshape(-1, 1) * 1.0\n",
        "labels_test = data_test[\"is_toxic\"].values.reshape(-1, 1) * 1.0\n",
        "labels_vali = data_vali[\"is_toxic\"].values.reshape(-1, 1) * 1.0"
      ],
      "metadata": {
        "id": "FqzeREh-qczN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = {\n",
        "    'sexuality': ['gay', 'lesbian', 'bisexual', 'homosexual', 'straight', 'heterosexual'], \n",
        "    'gender identity': ['trans', 'transgender', 'cis', 'nonbinary'],\n",
        "    'muslum-jew': ['muslim', 'jewish'], # 'christian', 'buddhist', 'catholic', 'protestant', 'sikh', 'taoist'\n",
        "    'christian': ['christian'],\n",
        "    'race': ['african', 'african american', 'black', 'white', 'european', 'hispanic', 'latino', 'latina', \n",
        "             'latinx', 'mexican', 'canadian', 'american', 'asian', 'indian', 'middle eastern', 'chinese', \n",
        "             'japanese']}\n",
        "\n",
        "group_names = list(terms.keys())\n",
        "num_groups = len(group_names)"
      ],
      "metadata": {
        "id": "rDI3HsW1GtAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_groups(text):\n",
        "    # Returns a boolean NumPy array of shape (n, k), where n is the number of comments, \n",
        "    # and k is the number of groups. Each entry (i, j) indicates if the i-th comment \n",
        "    # contains a term from the j-th group.\n",
        "    groups = np.zeros((text.shape[0], num_groups))\n",
        "    for ii in range(num_groups):\n",
        "        groups[:, ii] = text.str.contains('|'.join(terms[group_names[ii]]), case=False)\n",
        "    return groups\n",
        "\n",
        "groups_train = get_groups(data_train[\"comment\"])\n",
        "groups_test = get_groups(data_test[\"comment\"])\n",
        "groups_vali = get_groups(data_vali[\"comment\"])"
      ],
      "metadata": {
        "id": "R1No07V6G7Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Overall label proportion = %.1f%%\" % (labels_train.mean() * 100))\n",
        "\n",
        "group_stats = []\n",
        "for ii in range(num_groups):\n",
        "    group_proportion = groups_train[:, ii].mean()\n",
        "    group_pos_proportion = labels_train[groups_train[:, ii] == 1].mean()\n",
        "    group_stats.append([group_names[ii],\n",
        "                        \"%.2f%%\" % (group_proportion * 100), \n",
        "                        \"%.1f%%\" % (group_pos_proportion * 100)])\n",
        "group_stats = pd.DataFrame(group_stats, \n",
        "                           columns=[\"Topic group\", \"Group proportion\", \"Label proportion\"])\n",
        "group_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "IIIHWovDI_if",
        "outputId": "ca66caeb-1e04-43ed-8ead-87e4df55ba09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall label proportion = 9.7%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Topic group Group proportion Label proportion\n",
              "0        sexuality            1.30%            37.0%\n",
              "1  gender identity            5.34%             7.7%\n",
              "2       muslum-jew            0.92%            10.0%\n",
              "3        christian            0.72%             7.6%\n",
              "4             race            4.82%             9.2%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d22dab28-1185-49de-9529-1f03e7aff472\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic group</th>\n",
              "      <th>Group proportion</th>\n",
              "      <th>Label proportion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexuality</td>\n",
              "      <td>1.30%</td>\n",
              "      <td>37.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gender identity</td>\n",
              "      <td>5.34%</td>\n",
              "      <td>7.7%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>muslum-jew</td>\n",
              "      <td>0.92%</td>\n",
              "      <td>10.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>christian</td>\n",
              "      <td>0.72%</td>\n",
              "      <td>7.6%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>race</td>\n",
              "      <td>4.82%</td>\n",
              "      <td>9.2%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d22dab28-1185-49de-9529-1f03e7aff472')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d22dab28-1185-49de-9529-1f03e7aff472 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d22dab28-1185-49de-9529-1f03e7aff472');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "muslim_jews = groups_train[:, 2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enc6uqq8vqyU",
        "outputId": "4934d3e8-13ca-48a7-ae35-7cea2af832b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95692, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stanford Predifined Model\n",
        "zip_file_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "zip_file = urllib.request.urlopen(zip_file_url)\n",
        "archive = zipfile.ZipFile(io.BytesIO(zip_file.read()))"
      ],
      "metadata": {
        "id": "rQ_HpY8nJKHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "hparams = {\n",
        "    \"batch_size\": 128,\n",
        "    \"cnn_filter_sizes\": [128, 128, 128],\n",
        "    \"cnn_kernel_sizes\": [5, 5, 5],\n",
        "    \"cnn_pooling_sizes\": [2, 2, 5],\n",
        "    \"constraint_learning_rate\": 0.01,\n",
        "    \"embedding_dim\": 100,\n",
        "    \"embedding_trainable\": False,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"max_num_words\": 10000,\n",
        "    \"max_sequence_length\": 250\n",
        "}"
      ],
      "metadata": {
        "id": "fDNyd0cxl8id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "tokenizer = text.Tokenizer(num_words=hparams[\"max_num_words\"])\n",
        "tokenizer.fit_on_texts(data_train[\"comment\"])\n",
        "\n",
        "def prep_text(texts, tokenizer, max_sequence_length):\n",
        "    # Turns text into into padded sequences.\n",
        "    text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "    return sequence.pad_sequences(text_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "text_train = prep_text(data_train[\"comment\"], tokenizer, hparams[\"max_sequence_length\"])\n",
        "text_test = prep_text(data_test[\"comment\"], tokenizer, hparams[\"max_sequence_length\"])\n",
        "text_vali = prep_text(data_vali[\"comment\"], tokenizer, hparams[\"max_sequence_length\"])"
      ],
      "metadata": {
        "id": "Wmddb6Bglv-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "with archive.open(glove_file) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0].decode(\"utf-8\") \n",
        "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, hparams[\"embedding_dim\"]))\n",
        "num_words_in_embedding = 0\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        num_words_in_embedding += 1\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "U3VWWSHolj1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idMh2eVZo4b0",
        "outputId": "1d47b3f1-0b66-4e6d-a55b-c20c224682ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150978, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeling\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Embedding layer.\n",
        "    embedding_layer = layers.Embedding(\n",
        "        embedding_matrix.shape[0],\n",
        "        embedding_matrix.shape[1],\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=hparams[\"max_sequence_length\"],\n",
        "        trainable=hparams['embedding_trainable'])\n",
        "    model.add(embedding_layer)\n",
        "\n",
        "    # Convolution layers.\n",
        "    for filter_size, kernel_size, pool_size in zip(\n",
        "        hparams['cnn_filter_sizes'], hparams['cnn_kernel_sizes'],\n",
        "        hparams['cnn_pooling_sizes']):\n",
        "\n",
        "        conv_layer = layers.Conv1D(\n",
        "            filter_size, kernel_size, activation='relu', padding='same')\n",
        "        model.add(conv_layer)\n",
        "\n",
        "        pooled_layer = layers.MaxPooling1D(pool_size, padding='same')\n",
        "        model.add(pooled_layer)\n",
        "\n",
        "    # Add a flatten layer, a fully-connected layer and an output layer.\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZMT5MXHMo-eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch Modeling\n",
        "class TextClassifier(nn.ModuleList):\n",
        "  \n",
        "  def __init__(self, lam = 0.05):\n",
        "      super(TextClassifier, self).__init__()\n",
        "\n",
        "      # Embedding layer definition\n",
        "      self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix), freeze=False)\n",
        "      # self.embedding = nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], _weight=embedding_matrix) \n",
        "      # self.embedding.weight = embedding_matrix\n",
        "\n",
        "      # Convolution layers definition\n",
        "      self.conv_1 = nn.Conv1d(250, hparams['cnn_filter_sizes'][0], hparams['cnn_kernel_sizes'][0], padding='same').double()\n",
        "      self.pool_1 = nn.MaxPool1d(hparams['cnn_pooling_sizes'][0]).double()\n",
        "\n",
        "      self.conv_2 = nn.Conv1d(128, hparams['cnn_filter_sizes'][1], hparams['cnn_kernel_sizes'][1], padding='same').double()\n",
        "      self.pool_2 = nn.MaxPool1d(hparams['cnn_pooling_sizes'][1]).double()\n",
        "\n",
        "      self.conv_3 = nn.Conv1d(128, hparams['cnn_filter_sizes'][2], hparams['cnn_kernel_sizes'][2], padding='same').double()\n",
        "      self.pool_3 = nn.MaxPool1d(hparams['cnn_pooling_sizes'][2]).double()\n",
        "      \n",
        "       # Fully connected layer definition\n",
        "      self.fc1 = nn.Linear(640, 128).double()\n",
        "      self.fc2 = nn.Linear(128, 1).double()\n",
        "\n",
        "      # Fairness Parameters\n",
        "      self.m = 2 # Binary Label\n",
        "      self.k = 2 # Binary Sensitive Attribute\n",
        "\n",
        "      self.lam = lam\n",
        "      self.W = nn.Parameter(torch.zeros(self.k, self.m))\n",
        "    \n",
        "  def forward(self, x):\n",
        "\n",
        "    # Sequence of tokes is filterd through an embedding layer\n",
        "    x = self.embedding(x).double()\n",
        "    \n",
        "    # Convolution layer 1 is applied\n",
        "    x1 = self.conv_1(x)\n",
        "    x1 = torch.relu(x1)\n",
        "    # print(x1.shape)\n",
        "    x1 = self.pool_1(x1)\n",
        "    # print(x1.shape)\n",
        "\n",
        "    # Convolution layer 2 is applied\n",
        "    x2 = self.conv_2(x1)\n",
        "    print(x2.shape)\n",
        "    x2 = torch.relu((x2))\n",
        "    x2 = self.pool_2(x2)\n",
        "    # print(x2.shape)\n",
        "\n",
        "    # Convolution layer 3 is applied\n",
        "    x3 = self.conv_3(x2)\n",
        "    x3 = torch.relu(x3)\n",
        "    x3 = self.pool_3(x3)\n",
        "    # print(x3.shape)\n",
        "    # Flatten\n",
        "    x3 = torch.flatten(x3, 1)\n",
        "    # x3 = x3.reshape(x3.shape[0] * x3.shape[1] * x3.shape[2], -1)\n",
        "    # print(x3.shape)\n",
        "    \n",
        "\n",
        "    out1 = self.fc1(x3)\n",
        "    # print(out1.shape)\n",
        "    \n",
        "    # Second fully connected layer that outputs our 10 labels\n",
        "    out2 = self.fc2(out1)\n",
        "\n",
        "    out = torch.sigmoid(out2)\n",
        "      \n",
        "    return out\n",
        "\n",
        "  def fairness_regularizer(self, X, S):\n",
        "\n",
        "    current_batch_size = X.shape[0]      \n",
        "    summation = 0\n",
        "    \n",
        "    Y_hat = self.forward(X)\n",
        "\n",
        "    for i in range(current_batch_size):\n",
        "\n",
        "      # Binary output:\n",
        "      term = Y_hat[i] * Y_hat[i] * torch.matmul(self.W, torch.t(self.W))\n",
        "      summation += -torch.trace(term)\n",
        "      \n",
        "      term1 = Y_hat[i] * self.W\n",
        "      term2 = torch.matmul(term1, torch.t(S[i]).unsqueeze(0))\n",
        "      term3 = torch.matmul(term2, self.P_s_sqrt_inv)\n",
        "      summation += 2 * torch.trace(term3) - 1\n",
        "\n",
        "    return self.lam * summation"
      ],
      "metadata": {
        "id": "Rx5fKM8Sphw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextClassifier()\n",
        "\n",
        "current_batch = text_train[0:100]\n",
        "XTorch = torch.from_numpy(current_batch)\n",
        "print(XTorch)\n",
        "model(XTorch).size()\n",
        "# model(tex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35-iRBqHIf0S",
        "outputId": "9f82c071-49e0-4f03-bc57-612244d4f434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0,    0,    0,  ...,   18, 6240, 5074],\n",
            "        [   0,    0,    0,  ...,  585,  124,  318],\n",
            "        [4371, 2061, 7314,  ...,    1,  616,  127],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ..., 1017,    4, 2003],\n",
            "        [   0,    0,    0,  ..., 5237, 1934,  296],\n",
            "        [   0,    0,    0,  ..., 5237, 1934,  296]], dtype=torch.int32)\n",
            "torch.Size([100, 128, 50])\n",
            "torch.Size([100, 128, 50])\n",
            "torch.Size([100, 128, 25])\n",
            "torch.Size([100, 128, 5])\n",
            "torch.Size([100, 640])\n",
            "torch.Size([100, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "number_of_epochs = 5\n",
        "batch_size = 128\n",
        "number_of_data_points = text_train.shape[0]\n",
        "learning_rate_min = 10e-4\n",
        "learning_rate_max = 10^-4\n",
        "number_of_batches = number_of_data_points // batch_size + 1\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam([model.parameters(), model.W], lr=learning_rate_min)\n",
        "for _ in range(number_of_epochs):\n",
        "\n",
        "  for i in range(number_of_batches):\n",
        "    # Current_batch\n",
        "    start = i * batch_size\n",
        "    end = (i+1) * batch_size\n",
        "    if i != number_of_batches - 1:\n",
        "      currentX = torch.from_numpy(text_train[start:end])\n",
        "      currentY = torch.from_numpy(labels_train[start:end])\n",
        "    else:\n",
        "      currentX = torch.from_numpy(text_train[start:])\n",
        "      currentY = torch.from_numpy(labels_train[start:])\n",
        "    \n",
        "      # Feed the model\n",
        "      y_pred = model(currentX)\n",
        "      \n",
        "      # Loss calculation\n",
        "      loss = F.binary_cross_entropy(y_pred, currentY) + model.fairness_regularizer(X_S, S)\n",
        "      \n",
        "      # Clean gradientes\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Gradients calculation\n",
        "      loss.backward()\n",
        "      \n",
        "      model.W.grad.data.mul_(-learning_rate_max / learning_rate_min) # You can have \\eta_w here \n",
        "      # Gradients update\n",
        "      optimizer.step()\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Wy2o-8fGSZ",
        "outputId": "b54ea2c6-ec44-40c6-c334-39463b524aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 25])\n",
            "torch.Size([76, 128, 5])\n",
            "torch.Size([76, 640])\n",
            "torch.Size([76, 128])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 25])\n",
            "torch.Size([76, 128, 5])\n",
            "torch.Size([76, 640])\n",
            "torch.Size([76, 128])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 25])\n",
            "torch.Size([76, 128, 5])\n",
            "torch.Size([76, 640])\n",
            "torch.Size([76, 128])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 25])\n",
            "torch.Size([76, 128, 5])\n",
            "torch.Size([76, 640])\n",
            "torch.Size([76, 128])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 50])\n",
            "torch.Size([76, 128, 25])\n",
            "torch.Size([76, 128, 5])\n",
            "torch.Size([76, 640])\n",
            "torch.Size([76, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "x_test = torch.from_numpy(text_test[0:200])\n",
        "y_test = torch.from_numpy(labels_test[0:200])\n",
        "y_pred = model(x_test)\n",
        "final_preds = y_pred > 0.5\n",
        "test = y_test == 1\n",
        "\n",
        "acc = final_preds == test\n",
        "true_preds = acc.sum(axis=0)\n",
        "print(true_preds / 200)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTuGANhrvxAK",
        "outputId": "f874e654-e646-4074-80bd-864533043c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 128, 50])\n",
            "torch.Size([200, 128, 50])\n",
            "torch.Size([200, 128, 25])\n",
            "torch.Size([200, 128, 5])\n",
            "torch.Size([200, 640])\n",
            "torch.Size([200, 128])\n",
            "tensor([0.9750])\n"
          ]
        }
      ]
    }
  ]
}